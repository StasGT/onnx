{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbpnrqfaXpAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4194018a-cb15-420b-aeb6-7ff48b05d651"
      },
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "torch.set_grad_enabled(False);\n",
        "\n",
        "!pip install onnx onnxruntime\n",
        "\n",
        "import onnx\n",
        "import onnxruntime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.1)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.18.0 onnxruntime-1.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PII-dlPoXxIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facfd2a0-37c3-4587-d9d0-650538f9b50f"
      },
      "source": [
        "# COCO classes\n",
        "CLASSES = [\n",
        "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
        "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
        "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
        "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
        "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
        "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "class DETRdemo(nn.Module):\n",
        "    \"\"\"\n",
        "    Demo DETR implementation.\n",
        "\n",
        "    Demo implementation of DETR in minimal number of lines, with the\n",
        "    following differences wrt DETR in the paper:\n",
        "    * learned positional encoding (instead of sine)\n",
        "    * positional encoding is passed at input (instead of attention)\n",
        "    * fc bbox predictor (instead of MLP)\n",
        "    The model achieves ~40 AP on COCO val5k and runs at ~28 FPS on Tesla V100.\n",
        "    Only batch size 1 supported.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, hidden_dim=256, nheads=8,\n",
        "                 num_encoder_layers=6, num_decoder_layers=6):\n",
        "        super().__init__()\n",
        "\n",
        "        # create ResNet-50 backbone\n",
        "        self.backbone = resnet50()\n",
        "        del self.backbone.fc\n",
        "\n",
        "        # create conversion layer\n",
        "        self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
        "\n",
        "        # create a default PyTorch transformer\n",
        "        self.transformer = nn.Transformer(\n",
        "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
        "\n",
        "        # prediction heads, one extra class for predicting non-empty slots\n",
        "        # note that in baseline DETR linear_bbox layer is 3-layer MLP\n",
        "        self.linear_class = nn.Linear(hidden_dim, num_classes + 1)\n",
        "        self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
        "\n",
        "        # output positional encodings (object queries)\n",
        "        self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
        "\n",
        "        # spatial positional encodings\n",
        "        # note that in baseline DETR we use sine positional encodings\n",
        "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # propagate inputs through ResNet-50 up to avg-pool layer\n",
        "        x = self.backbone.conv1(inputs)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        # convert from 2048 to 256 feature planes for the transformer\n",
        "        h = self.conv(x)\n",
        "\n",
        "        # construct positional encodings\n",
        "        H, W = h.shape[-2:]\n",
        "        pos = torch.cat([\n",
        "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
        "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
        "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
        "\n",
        "        # propagate through the transformer\n",
        "        h = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1),\n",
        "                             self.query_pos.unsqueeze(1)).transpose(0, 1)\n",
        "\n",
        "        # finally project transformer outputs to class labels and bounding boxes\n",
        "\n",
        "        #return torch.cat((self.linear_class(h), self.linear_bbox(h).sigmoid()), dim=2)\n",
        "        return self.linear_class(h).softmax(-1), self.linear_bbox(h).sigmoid()\n",
        "        #return {'pred_logits': self.linear_class(h), 'pred_boxes': self.linear_bbox(h).sigmoid()}\n",
        "\n",
        "detr_demo = DETRdemo(num_classes=91)\n",
        "state_dict = torch.hub.load_state_dict_from_url(\n",
        "    url='https://dl.fbaipublicfiles.com/detr/detr_demo-da2a99e9.pth',\n",
        "    map_location='cpu', check_hash=True)\n",
        "detr_demo.load_state_dict(state_dict)\n",
        "detr_demo.eval();"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr_demo-da2a99e9.pth\" to /root/.cache/torch/hub/checkpoints/detr_demo-da2a99e9.pth\n",
            "100%|██████████| 79.3M/79.3M [00:01<00:00, 69.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCu7ZLV3X8tl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4837f2-9ba0-4436-b5bb-a10d6df26cb3"
      },
      "source": [
        "detr = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
        "detr.eval()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/detr/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 65.8MB/s]\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth\" to /root/.cache/torch/hub/checkpoints/detr-r50-e632da11.pth\n",
            "100%|██████████| 159M/159M [00:02<00:00, 60.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DETR(\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (class_embed): Linear(in_features=256, out_features=92, bias=True)\n",
              "  (bbox_embed): MLP(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (query_embed): Embedding(100, 256)\n",
              "  (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (backbone): Joiner(\n",
              "    (0): Backbone(\n",
              "      (body): IntermediateLayerGetter(\n",
              "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (bn1): FrozenBatchNorm2d()\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "        (layer1): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): FrozenBatchNorm2d()\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer2): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): FrozenBatchNorm2d()\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer3): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): FrozenBatchNorm2d()\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (4): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (5): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer4): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "              (1): FrozenBatchNorm2d()\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): FrozenBatchNorm2d()\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): FrozenBatchNorm2d()\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): FrozenBatchNorm2d()\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): PositionEmbeddingSine()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIVpoOIYYOfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adedf1a5-18a6-4d2c-ad4e-619ff79eecae"
      },
      "source": [
        "url = 'https://static.independent.co.uk/s3fs-public/thumbnails/image/2017/09/13/12/surfer.jpg?w968h681'\n",
        "im = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "transform = T.Compose([\n",
        "                        T.Resize(800),\n",
        "                        T.ToTensor(),\n",
        "                        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                      ])\n",
        "\n",
        "sample_input = transform(im).unsqueeze(0)\n",
        "\n",
        "\n",
        "probs, boxes = detr_demo(sample_input)\n",
        "\n",
        "output_onnx_path = \"detr_model.onnx\"\n",
        "\n",
        "torch.onnx.export(\n",
        "    detr_demo,\n",
        "    sample_input,\n",
        "    output_onnx_path,\n",
        "    opset_version=17, # Specify an appropriate ONNX opset version\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"logits\", \"boxes\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}} # Optional: for dynamic batch size\n",
        ")\n",
        "print(f\"Model exported to {output_onnx_path}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py:1824: UserWarning: Provided key output for dynamic axes is not a valid input/output name\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model exported to detr_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as rt\n",
        "import numpy as np\n",
        "\n",
        "sess = rt.InferenceSession(output_onnx_path)\n",
        "\n",
        "\n",
        "input_name = sess.get_inputs()[0].name\n",
        "output_name = sess.get_outputs()[0].name\n",
        "\n",
        "# Run inference with a dummy input (convert to numpy)\n",
        "onnx_output = sess.run([output_name], {input_name: sample_input.detach().cpu().numpy()})\n"
      ],
      "metadata": {
        "id": "ZV-GZg7QgMvM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sess = rt.InferenceSession(output_onnx_path)\n",
        "\n",
        "input_name = sess.get_inputs()[0].name\n",
        "output_name = [sess.get_outputs()[0].name, sess.get_outputs()[1].name]\n",
        "\n",
        "\n",
        "# Run inference with a dummy input (convert to numpy)\n",
        "onnx_output = sess.run(output_name, {input_name: sample_input.detach().cpu().numpy()})"
      ],
      "metadata": {
        "id": "vevwL7-VhJkL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "example_inputs = (sample_input, )\n",
        "onnx_inputs = [tensor.numpy(force=True) for tensor in example_inputs]\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"./detr_model.onnx\", providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "onnxruntime_input = {input_arg.name: input_value for input_arg, input_value in zip(ort_session.get_inputs(), onnx_inputs)}\n",
        "# ONNX Runtime returns a list of outputs\n",
        "start = time.time()\n",
        "logits, boxes = ort_session.run(None, onnxruntime_input)\n",
        "print(f'Inference time: {(time.time()-start):0.2f}')\n",
        "probas = logits[0, :, :-1]\n",
        "keep = probas.max(-1) > 0.7"
      ],
      "metadata": {
        "id": "VLNY2fL_NPIN",
        "outputId": "f9eb8f9c-1ef2-4ebd-c9aa-1a40ef2adc5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference time: 6.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = probas[keep].argmax(1)\n",
        "\n",
        "\n",
        "for i, j in enumerate(p):\n",
        "  print(f'{CLASSES[j]}: {probas[keep][i, j]:0.2f}')\n",
        "  print(boxes[0, keep][i])"
      ],
      "metadata": {
        "id": "thXYjVmyzlgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# colors for visualization\n",
        "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
        "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
        "\n",
        "# for output bounding box post-processing\n",
        "def box_cxcywh_to_xyxy(x):\n",
        "    #x = torch.from_numpy(x)\n",
        "    x_c, y_c, w, h = np.hsplit(x, 4)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
        "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return np.stack(b, axis=2)\n",
        "\n",
        "def rescale_bboxes(out_bbox, size):\n",
        "    img_w, img_h = size\n",
        "    b = box_cxcywh_to_xyxy(out_bbox)\n",
        "    b = b * np.array([img_w, img_h, img_w, img_h])\n",
        "    return b\n",
        "\n",
        "def plot_results(pil_img, prob, boxes):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    plt.imshow(pil_img)\n",
        "    ax = plt.gca()\n",
        "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes[:, 0, :].tolist(), COLORS * 100):\n",
        "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                   fill=False, color=c, linewidth=3))\n",
        "        cl = p.argmax()\n",
        "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
        "        ax.text(xmin, ymin, text, fontsize=15,\n",
        "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "bboxes_scaled = rescale_bboxes(boxes[0, keep], im.size)\n",
        "plot_results(im, probas[keep], bboxes_scaled)"
      ],
      "metadata": {
        "id": "jb3PBkaZBVaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "torch_logits, torch_boxes = detr_demo(sample_input)\n",
        "print(time.time()-start)\n",
        "probas = torch_logits[0, :, :-1]\n",
        "\n",
        "keep = probas.max(-1).values > 0.7\n",
        "\n",
        "p = probas[keep].argmax(1)\n",
        "\n",
        "\n",
        "for i, j in enumerate(p):\n",
        "  print(f'{CLASSES[j]}: {probas[keep][i, j]:0.2f}')\n",
        "  print(torch_boxes[0, keep][i])"
      ],
      "metadata": {
        "id": "U6yKGIOXPYsE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}